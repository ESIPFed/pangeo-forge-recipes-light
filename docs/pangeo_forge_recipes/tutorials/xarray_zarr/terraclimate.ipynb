{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex NetCDF to Zarr Recipe: TerraClimate \n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "From http://www.climatologylab.org/terraclimate.html:\n",
    "\n",
    "> TerraClimate is a dataset of monthly climate and climatic water balance for global terrestrial surfaces from 1958-2019. These data provide important inputs for ecological and hydrological studies at global scales that require high spatial resolution and time-varying data. All data have monthly temporal resolution and a ~4-km (1/24th degree) spatial resolution. The data cover the period from 1958-2019. We plan to update these data periodically (annually).\n",
    "\n",
    "## What makes it tricky\n",
    "\n",
    "This is an advanced example that illustrates the following concepts\n",
    "- _Multiple variables in different files_: There is one file per year for a dozen different variables.\n",
    "- _Complex Preprocessing_: We want to apply different preprocessing depending on the variable. This example shows how.\n",
    "- _Inconsistent size of data in input files_: This means we have to scan each input file and cache its metadata before we can start writing the target.\n",
    "\n",
    "This recipe requires a new storage target, a `metadata_cache`. In this example, this is just another directory. You could hypothetically use a database or other key/value store for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from pangeo_forge_recipes.transforms import OpenURLWithFSSpec, OpenWithXarray, StoreToZarr\n",
    "\n",
    "from pangeo_forge_recipes.patterns import FilePattern, ConcatDim, MergeDim\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Filename Pattern \n",
    "\n",
    "To keep this example smaller, we just use two years instead of the whole record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FilePattern {'time': 1, 'variable': 14}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chunks = {\"lat\": 1024, \"lon\": 1024, \"time\": 12}\n",
    "\n",
    "# only do two years to keep the example small; it's still big!\n",
    "years = list(range(2000, 2002))\n",
    "variables = [\n",
    "    \"aet\",\n",
    "    \"def\",\n",
    "    \"pet\",\n",
    "    \"ppt\",\n",
    "    \"q\",\n",
    "    \"soil\",\n",
    "    \"srad\",\n",
    "    \"swe\",\n",
    "    \"tmax\",\n",
    "    \"tmin\",\n",
    "    \"vap\",\n",
    "    \"ws\",\n",
    "    \"vpd\",\n",
    "    \"PDSI\",\n",
    "]\n",
    "\n",
    "def make_filename(variable, time):\n",
    "    return f\"http://thredds.northwestknowledge.net:8080/thredds/fileServer/TERRACLIMATE_ALL/data/TerraClimate_{variable}_{time}.nc\"\n",
    "\n",
    "pattern = FilePattern(\n",
    "    make_filename,\n",
    "    ConcatDim(name=\"time\", keys=years),\n",
    "    MergeDim(name=\"variable\", keys=variables)\n",
    ")\n",
    "pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({Dimension(name='time', operation=<CombineOp.CONCAT: 2>): Position(value=0, indexed=False),\n",
       "  Dimension(name='variable', operation=<CombineOp.MERGE: 1>): Position(value=0, indexed=False)},\n",
       " 'http://thredds.northwestknowledge.net:8080/thredds/fileServer/TERRACLIMATE_ALL/data/TerraClimate_aet_2000.nc')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, filename in pattern.items():\n",
    "    break\n",
    "key, filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Output Directory\n",
    "Here we will create a temporary directory to write our output dataset to. We could also write to cloud storage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/mb/7d7yq_4j2qgdfm_j3j4tsyl40000gn/T/tmpx5ms0idr/output.zarr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "td = TemporaryDirectory()\n",
    "target_path = td.name + \"/output.zarr\"\n",
    "target_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Preprocessing Functions\n",
    "\n",
    "These functions apply masks for each variable to remove invalid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangeo_forge_recipes.transforms import Indexed, T\n",
    "\n",
    "def _apply_mask(key, da):\n",
    "    \"\"\"helper function to mask DataArrays based on a threshold value\"\"\"\n",
    "    mask_opts = {\n",
    "    \"PDSI\": (\"lt\", 10),\n",
    "    \"aet\": (\"lt\", 32767),\n",
    "    \"def\": (\"lt\", 32767),\n",
    "    \"pet\": (\"lt\", 32767),\n",
    "    \"ppt\": (\"lt\", 32767),\n",
    "    \"ppt_station_influence\": None,\n",
    "    \"q\": (\"lt\", 2147483647),\n",
    "    \"soil\": (\"lt\", 32767),\n",
    "    \"srad\": (\"lt\", 32767),\n",
    "    \"swe\": (\"lt\", 10000),\n",
    "    \"tmax\": (\"lt\", 200),\n",
    "    \"tmax_station_influence\": None,\n",
    "    \"tmin\": (\"lt\", 200),\n",
    "    \"tmin_station_influence\": None,\n",
    "    \"vap\": (\"lt\", 300),\n",
    "    \"vap_station_influence\": None,\n",
    "    \"vpd\": (\"lt\", 300),\n",
    "    \"ws\": (\"lt\", 200),\n",
    "    }   \n",
    "    if mask_opts.get(key, None):\n",
    "        op, val = mask_opts[key]\n",
    "        if op == \"lt\":\n",
    "            da = da.where(da < val)\n",
    "        elif op == \"neq\":\n",
    "            da = da.where(da != val)\n",
    "    return da\n",
    "\n",
    "class Munge(beam.PTransform):\n",
    "    \"\"\"\n",
    "    Apply cleaning transformations to Datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _preproc(item: Indexed[T]) -> Indexed[T]:\n",
    "        \"\"\"custom preprocessing function for terraclimate data\"\"\"\n",
    "        index, ds = item\n",
    "        \n",
    "        # invalid unicode in source data. This attr replacement is a fix.\n",
    "        fixed_attrs = {'method': 'These layers from TerraClimate were derived from the essential climate variables of TerraClimate. Water balance variables, actual evapotranspiration, climatic water deficit, runoff, soil moisture, and snow water equivalent were calculated using a water balance model and plant extractable soil water capacity derived from Wang-Erlandsson et al (2016).', 'title': 'TerraClimate: monthly climate and climatic water balance for global land surfaces', 'summary': 'This archive contains a dataset of high-spatial resolution (1/24th degree, ~4-km) monthly climate and climatic water balance for global terrestrial surfaces from 1958-2015. These data were created by using climatically aided interpolation, combining high-spatial resolution climatological normals from the WorldClim version 1.4 and version 2 datasets, with coarser resolution time varying (i.e. monthly) data from CRU Ts4.0 and JRA-55 to produce a monthly dataset of precipitation, maximum and minimum temperature, wind speed, vapor pressure, and solar radiation. TerraClimate additionally produces monthly surface water balance datasets using a water balance model that incorporates reference evapotranspiration, precipitation, temperature, and interpolated plant extractable soil water capacity.', 'keywords': 'WORLDCLIM,global,monthly, temperature,precipitation,wind,radiation,vapor pressure,evapotranspiration,water balance,soil water capacity,snow water equivalent,runoff', 'id': 'Blank', 'naming_authority': 'edu.uidaho.nkn', 'keywords_vocabulary': 'None', 'cdm_data_type': 'GRID', 'history': 'Created by John Abatzoglou, University of California Merced', 'date_created': '2021-04-22', 'creator_name': 'John Abatzoglou', 'creator_url': 'http://climate.nkn.uidaho.edu/TerraClimate', 'creator_role': 'Principal Investigator', 'creator_email': 'jabatzoglou@ucmerced.edu', 'institution': 'University of California Merced', 'project': 'Global Dataset of Monthly Climate and Climatic Water Balance (1958-2015)', 'processing_level': 'Gridded Climate Projections', 'acknowledgment': 'Please cite the references included herein. We also acknowledge the WorldClim datasets (Fick and Hijmans, 2017; Hijmans et al., 2005) and the CRU Ts4.0 (Harris et al., 2014) and JRA-55 (Kobayashi et al., 2015) datasets.', 'geospatial_lat_min': -89.979164, 'geospatial_lat_max': 89.979164, 'geospatial_lon_min': -179.97917, 'geospatial_lon_max': 179.97917, 'geospatial_vertical_min': 0.0, 'geospatial_vertical_max': 0.0, 'time_coverage_start': '1958-01-01T00:0', 'time_coverage_end': '1958-12-01T00:0', 'time_coverage_duration': 'P1Y', 'time_coverage_resolution': 'P1M', 'standard_nam_vocabulary': 'CF-1.0', 'license': 'No restrictions', 'contributor_name': 'Katherine Hegewisch', 'contributor_role': 'Postdoctoral Fellow', 'contributor_email': 'khegewisch@ucmerced.edu', 'publisher_name': 'Northwest Knowledge Network', 'publisher_url': 'http://www.northwestknowledge.net', 'publisher_email': 'info@northwestknowledge.net', 'date_modified': '2021-04-22', 'date_issued': '2021-04-22', 'geospatial_lat_units': 'decimal degrees north', 'geospatial_lat_resolution': -0.041666668, 'geospatial_lon_units': 'decimal degrees east', 'geospatial_lon_resolution': 0.041666668, 'geospatial_vertical_units': 'None', 'geospatial_vertical_resolution': 0.0, 'geospatial_vertical_positive': 'Up', 'references': 'Abatzoglou, J.T., S.Z. Dobrowski, S.A. Parks, and K.C. Hegewisch, 2017, High-resolution global dataset of monthly climate and climatic water balance from 1958-2015, submitted to Scientific Data.', 'source': 'WorldClim v2.0 (2.5m), CRU Ts4.0, JRA-55', 'version': 'v1.0', 'Conventions': 'CF-1.6'}\n",
    "        ds.attrs = fixed_attrs\n",
    "        \n",
    "        rename = {}\n",
    "\n",
    "        station_influence = ds.get(\"station_influence\", None)\n",
    "\n",
    "        if station_influence is not None:\n",
    "            ds = ds.drop_vars(\"station_influence\")\n",
    "\n",
    "        var = list(ds.data_vars)[0]\n",
    "        \n",
    "        rename_vars = {'PDSI': 'pdsi'}\n",
    "\n",
    "        if var in rename_vars:\n",
    "            rename[var] = rename_vars[var]\n",
    "\n",
    "        if \"day\" in ds.coords:\n",
    "            rename[\"day\"] = \"time\"\n",
    "\n",
    "        if station_influence is not None:\n",
    "            ds[f\"{var}_station_influence\"] = station_influence\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            ds[var] = _apply_mask(var, ds[var])\n",
    "        if rename:\n",
    "            ds = ds.rename(rename)\n",
    "        return index, ds\n",
    "\n",
    "    def expand(self, pcoll: beam.PCollection) -> beam.PCollection:\n",
    "        return pcoll | beam.Map(self._preproc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "We are now ready to create the processing pipeline.\n",
    "\n",
    "Below we chain together multiple processing steps.\n",
    "1. Initalize the pipeline with the list of input file patterns\n",
    "2. Use Fsspec to open each file url and create Fsspec file objects\n",
    "3. Pass the Fsspec file objects to Xarray to open as Xarray Datasets\n",
    "4. Pass the Xarray Datasets to our custom preprocessing function (named `Munge`) \n",
    "   to apply our preprocessing and cleaning logic\n",
    "5. Pass the cleaned Xarray Dataset to the `StoreToZarr` method to combine and\n",
    "   write the Datasets to a single Zarr Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ChainedPTransform(PTransform) label=[Create|OpenURLWithFSSpec|OpenWithXarray|Munge|StoreToZarr] at 0x1790e5130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = (\n",
    "    beam.Create(pattern.items())\n",
    "    | OpenURLWithFSSpec()\n",
    "    | OpenWithXarray(file_type=pattern.file_type)\n",
    "    | Munge() # New pre-processor\n",
    "    | StoreToZarr(\n",
    "        target=target_path,\n",
    "        target_chunks = target_chunks,\n",
    "        combine_dims=pattern.combine_dim_keys,\n",
    "    )\n",
    ")\n",
    "transforms\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will create a `Beam` pipeline and pass our in of transforms to that pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class 'pangeo_forge_recipes.types.Index'>' in '[7]: Create|OpenURLWithFSSpec|OpenWithXarray|Munge|StoreToZarr/StoreToZarr/DetermineSchema/CombinePerKey(CombineXarraySchemas)/GroupByKey'. \n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    p | transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and Plot Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_target = xr.open_zarr(target_path, consolidated=True)\n",
    "print(ds_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example calculation, we compute and plot the seasonal climatology of soil moisture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.set_options(keep_attrs=True):\n",
    "    soil_clim = ds_target.soil.groupby('time.season').mean('time').coarsen(lon=12, lat=12).mean()\n",
    "soil_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_clim.plot(col='season', col_wrap=2, robust=True, figsize=(18, 8))"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": false,
   "timeout": 3000
  },
  "kernelspec": {
   "display_name": "pangeo-forge-recipes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8472a85c0cbfd90fc84f178c7f47d34e20396f42fa331cce9968659ce876ac9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
